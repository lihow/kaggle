{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #torch是关于运算的包\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms, models #torchvision则是打包了一些数据集\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torchnet import meter\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from progressbar import * #进度条\n",
    "#如果多gpu运行，屏蔽下一句\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#残差块的第一种实现方式，对应于resnet_18\n",
    "class ResidualBlock_1(nn.Module): ## 继承 torch 的 Module\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResidualBlock_1, self).__init__() #  # 继承 __init__ 功能\n",
    "        #super() 函数是用于调用父类(超类)的一个方法 调用nn.Module\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ##inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出\n",
    "            nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            #out_size_w = (input_size_w - kernel_size + 2*padding)/stride + 1 = input_size_w\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, bias=False),# padding Default: 0 \n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "    def forward(self, x):## 这同时也是 Module 中的 forward 功能\n",
    "        #在pytorch中只需要定义forward函数即可, 反向传播backward的部分在你使用autograd时会自动生成\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        #，nn.Conv2d是一个类，而F.conv2d()是一个函数，\n",
    "        #而nn.Conv2d的forward()函数实现是用F.conv2d()实现的\n",
    "        #（在Module类里的__call__实现了forward()函数的调用，\n",
    "        #所以当实例化nn.Conv2d类时，forward()函数也被执行了\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock_1, 64, 2, stride=1)#output_w = 32\n",
    "        self.layer2 = self.make_layer(ResidualBlock_1, 128, 2, stride=2)#output_w = 16\n",
    "        self.layer3 = self.make_layer(ResidualBlock_1, 256, 2, stride=2)#output_w = 8\n",
    "        self.layer4 = self.make_layer(ResidualBlock_1, 512, 2, stride=2)#out_put_w = 4\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channel, channels, stride))\n",
    "            self.in_channel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#残差块的第二种实现方式 对应于resnet_34\n",
    "class ResidualBlock_2(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock_2, self).__init__()\n",
    "        self.left=nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.right=shortcut\n",
    "    def forward(self, x):\n",
    "        out=self.left(x)\n",
    "        residual=x if self.right is None else self.right(x)\n",
    "        out+=residual\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet_34(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_34, self).__init__()\n",
    "        #前几层图像转换\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),#[112, 112, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1)#[56, 56, 64] (112 + 1*2 - 2)/2=56\n",
    "            #nn.MaxPool1d(kernel_size, stride=None, padding=0,...) \n",
    "        )\n",
    "        #重复的layer,分别有3， 4， 6， 3个residual block\n",
    "        self.layer1=self._make_layer(64, 64, 3)#[56, 56, 64]\n",
    "        self.layer2=self._make_layer(64, 128, 4, stride=2)#[28, 28, 128]\n",
    "        self.layer3=self._make_layer(128, 256, 6, stride=2)#[14, 14, 256]\n",
    "        self.layer4=self._make_layer(256, 512, 3, stride=2)#[7, 7, 512]\n",
    "        #分类用的全连接\n",
    "        self.fc=nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, in_channel, out_channel, block_num, stride=1):\n",
    "        shortcut=nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 1, stride, bias=False),#(56 - 1)/1 +1 =56   (56-1)/2+1=28\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        layers=[]\n",
    "        layers.append(ResidualBlock_2(in_channel, out_channel, stride, shortcut))\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock_2(out_channel, out_channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x=self.pre(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=F.avg_pool2d(x, 7)\n",
    "        x=x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResNet_18_34(layer_num=18):\n",
    "    if layer_num == 18:\n",
    "        return ResNet_18(ResidualBlock_1)\n",
    "    elif layer_num == 34:\n",
    "        return ResNet_34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#残差块的第三种实现方式，其中 resnet-18, 34采用BasicBlock方式，50,101采用BottleNeck方式\n",
    "def conv3x3(in_channel, out_channel, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=3, \\\n",
    "                     stride=stride, padding=1, bias=False)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion=1\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channel, out_channel, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channel, out_channel)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out+=residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion=4\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(out_channel, out_channel*4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        self.in_channel = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)#[3, 224, 224]->[64, 112, 112]\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)#[64, 112, 112]->[64, 56, 56]\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])#[64, 56, 56]->[64*expan, 56, 56]-----[64/256, 56, 56]  expan=1/4\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)#[[64/256, 56, 56]->[128*expan, 28, 28]---[128/512, 28. 28]\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)#[128/512, 28. 28]->[256*expan, 14, 14]---[256/1024, 14. 14]\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)#[256/1024, 14. 14]->[512*expan, 7, 7]---[512/2048, 7, 7]\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)#[512/2048, 7, 7]->[512/2048, 1]\n",
    "        self.fc = nn.Linear(512*block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2./n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    def _make_layer(self, block, out_channel, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != out_channel*block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, out_channel*block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel*block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel, out_channel, stride, downsample))\n",
    "        self.in_channel = out_channel*block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_channel, out_channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet(layers_num=18):\n",
    "    if layers_num == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    elif layers_num == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "    elif layers_num == 50:\n",
    "        model = ResNet(BottleNeck, [3, 4, 6, 3])\n",
    "    elif layers_num == 101:\n",
    "        model = ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resnet(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2int = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "int2lable = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndValData(Dataset):\n",
    "    def __init__(self, img_path, csv_path, train=True, transforms=None):\n",
    "        '''\n",
    "        获得所有图片路径，并划分训练集、验证集\n",
    "        '''\n",
    "        self.train = train\n",
    "        files = natsorted(glob.glob(img_path + '/*'))\n",
    "        labels = pd.read_csv(csv_path).values[:, 1]\n",
    "        files_num = len(files)\n",
    "        break_point = int(0.9*files_num)\n",
    "        if self.train:\n",
    "            self.img_name = files[: break_point]\n",
    "            self.img_label = labels[: break_point]\n",
    "        else:\n",
    "            self.img_name = files[break_point: ]\n",
    "            self.img_label = labels[break_point: ]\n",
    "         \n",
    "   \n",
    "\n",
    "        #数据增强\n",
    "        if transforms is None:\n",
    "            normalize = T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "            #训练集用数据增强\n",
    "            if self.train:\n",
    "                self.transforms = T.Compose([\n",
    "                    #T.RandomCrop(224, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32`，\n",
    "                    T.Resize(256),\n",
    "                    T.RandomResizedCrop(224),\n",
    "                    T.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "                    #T.RandomVerticalFlip(),\n",
    "                    T.ToTensor(),\n",
    "                    normalize \n",
    "                ])\n",
    "            else:\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    #T.CenterCrop(224),#中心裁剪\n",
    "                    T.ToTensor(),\n",
    "                    normalize \n",
    "                ])\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回数据集中所有图片的个数\n",
    "        '''\n",
    "        return len(self.img_name)\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        返回一张图片的数据\n",
    "        '''\n",
    "        img_path = self.img_name[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transforms(img)\n",
    "        label = label2int[self.img_label[index]]\n",
    "        return img, label\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, img_path, transforms=None):\n",
    "        files = natsorted(glob.glob(img_path + '/*'))\n",
    "        self.img_name = files\n",
    "        if transforms is None:\n",
    "            normalize = T.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "            self.transforms =  T.Compose([\n",
    "                T.Resize(224),\n",
    "                T.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_name[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transforms(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'data/train'\n",
    "csv_path = 'data/trainLabels.csv'\n",
    "test_img_path = 'data/test'\n",
    "train_dataset = TrainAndValData(train_img_path, csv_path, train=True)\n",
    "val_dataset = TrainAndValData(train_img_path, csv_path, train=False)\n",
    "#test_dataset = TestData(test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len is 45000\n",
      "torch.Size([3, 224, 224])\n",
      "6\n",
      "val len is 5000\n",
      "torch.Size([3, 224, 224])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print('train len is %d' % len(train_dataset))\n",
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][1])#打印标签\n",
    "print('val len is %d' % len(val_dataset))\n",
    "print(val_dataset[0][0].shape)\n",
    "print(val_dataset[0][1])\n",
    "#print('test len is %d' % len(test_dataset))\n",
    "#print(test_dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 135   #遍历数据集次数\n",
    "BATCH_SIZE = 60      #批处理尺寸(batch_size)\n",
    "#LR = 0.001        #学习率\n",
    "lr = 0.001\n",
    "lr_decay = 0.95\n",
    "weight_decay = 1e-4\n",
    "model_path = 'model/resnet/resnet_101.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "the epoch 0, the train loss is 0.032695, the test loss is 0.028015, the test acc is 0.354839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhw/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/lhw/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BottleNeck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the epoch 1, the train loss is 0.028231, the test loss is 0.025267, the test acc is 0.442958\n",
      "the epoch 2, the train loss is 0.025256, the test loss is 0.024139, the test acc is 0.457514\n",
      "the epoch 3, the train loss is 0.023346, the test loss is 0.021555, the test acc is 0.547600\n",
      "the epoch 4, the train loss is 0.021978, the test loss is 0.022230, the test acc is 0.534225\n",
      "the epoch 5, the train loss is 0.020934, the test loss is 0.017715, the test acc is 0.610936\n",
      "the epoch 6, the train loss is 0.019900, the test loss is 0.015272, the test acc is 0.667191\n",
      "the epoch 7, the train loss is 0.019080, the test loss is 0.015517, the test acc is 0.666601\n",
      "the epoch 8, the train loss is 0.018382, the test loss is 0.018085, the test acc is 0.621164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-76:\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Process Process-75:\n",
      "Process Process-73:\n",
      "Process Process-74:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-14-415013d5b31f>\", line 52, in __getitem__\n",
      "    img = self.transforms(img)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/lhw/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1765, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6275fc553864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m#更新指标\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtrain_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4) \n",
    "\n",
    "device = torch.device(\"cuda:2\")\n",
    "#net = ResNet_18_34(34)\n",
    "\n",
    "net = resnet(50)\n",
    "#net = net.to(device)\n",
    "##单GPU\n",
    "#net = net.cuda()\n",
    "##多GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net, device_ids=[0,1])\n",
    "net = net.cuda()\n",
    "# 定义损失函数和优化方式\n",
    "criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "#保存模型判断条件\n",
    "max_val_acc = 0\n",
    "pre_epoch = 0\n",
    "max_interval_epoch = 10\n",
    "pre_train_loss = 100000\n",
    "\n",
    "print(\"Start Training...\")\n",
    "for epoch in range(100):\n",
    "    #训练集\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        #inputs, labels = inputs.to(device), labels.to(device) # 注意需要复制到GPU\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #更新指标\n",
    "        train_count += labels.size(0)\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= train_count\n",
    "\n",
    "    #验证集\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    val_count = 0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data\n",
    "        #inputs, labels = inputs.to(device), labels.to(device) # 注意需要复制到GPU\n",
    "        inputs, labels =  inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #更新指标\n",
    "        val_count += 1\n",
    "        val_loss += loss.item()\n",
    "        _, predict = outputs.max(1)\n",
    "        val_count += labels.size(0)\n",
    "        val_acc += (predict == labels).sum().item()\n",
    "    val_acc /= val_count\n",
    "    val_loss /= val_count\n",
    "    # print the loss and accuracy\n",
    "    print('the epoch %d, the train loss is %f, the test loss is %f, the test acc is %f' % (epoch, train_loss, val_loss, val_acc))\n",
    "\n",
    "    #保存模型\n",
    "    if val_acc > max_val_acc:\n",
    "        max_val_acc = val_acc\n",
    "        pre_epoch = epoch\n",
    "        torch.save(net, model_path)#保存整个神经网络的的结构信息和模型参数信息，save的对象是网络net\n",
    "    if epoch - pre_epoch > max_interval_epoch:\n",
    "        print('early stop')\n",
    "        break\n",
    "\n",
    "    #如果损失不载下降，则降低学习率\n",
    "    if train_loss > pre_train_loss:\n",
    "        lr = lr*lr_decay\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    pre_train_loss = pre_train_loss\n",
    "print(\"Done Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
