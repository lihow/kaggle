{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imsave\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import transform, filters, exposure\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "int2lable = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片数据持久化，保存到本地，供下次直接调用 由于测试集比较大，本次只抽取训练集\n",
    "def data_preprocessing(data_path, resize=True, img_rows=32, img_cols=32):\n",
    "    if (os.path.exists(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        #and os.path.exists(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        and os.path.exists(data_path + '/' + 'labels.npy')):\n",
    "        print('data have already processed')\n",
    "    else:\n",
    "        ### Image preprocessing ###\n",
    "        if resize == True:\n",
    "            if not os.path.exists(data_path + \"/trainResized\"):\n",
    "                os.makedirs(data_path + \"/trainResized\")\n",
    "            if not os.path.exists(data_path + \"/testResized\"):\n",
    "                os.makedirs(data_path + \"/testResized\")\n",
    "        for set_type in ['train']:#, 'test']:\n",
    "            files = natsorted(glob.glob(data_path + '/' + set_type + '/*'))\n",
    "            data = np.zeros((len(files), img_rows, img_cols, 3))\n",
    "            for i, file_path in enumerate(files):\n",
    "                '''\n",
    "                img = imread(file_path, as_grey=True) #读入的图为[0, 1]图\n",
    "                img_resized = resize(img, (img_rows, img_cols))\n",
    "                data[i] = img_resized\n",
    "                #Save image\n",
    "                new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                imsave(new_name, img_resized)\n",
    "                '''\n",
    "                #利用opencv读取图片\n",
    "                img = cv2.imread(file_path) #读入彩色图\n",
    "                if resize == True:\n",
    "                    img_resized = cv2.resize(img, (img_rows, img_cols))#读入的[0, 255]的图\n",
    "                    data[i] = img_resized\n",
    "                    #Save image\n",
    "                    new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                    cv2.imwrite(new_name, img_resized) \n",
    "                else:\n",
    "                    data[i] = img\n",
    "            #Add channel/filter dimension [222, 32, 32] => [222, 1, 32, 32]\n",
    "            #train_img = np.stack(train_img)[..., None]\n",
    "            #data = data[:, :, :, np.newaxis]\n",
    "            data = data.astype('float32')\n",
    "            data /= 255\n",
    "            np.save(data_path + '/' + set_type + '_' + str(img_rows) +  '_' + str(img_cols) + '.npy', data)\n",
    "        ### Labels preprocessing ###\n",
    "        y_train = pd.read_csv(data_path + '/trainLabels.csv').values[:, 1]\n",
    "        #Convert one-hot vectors\n",
    "        Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    "        for i in range(y_train.shape[0]):\n",
    "            Y_train[i][label2int[y_train[i]]] = 1\n",
    "        np.save(data_path + '/' + 'labels.npy', Y_train)\n",
    "    X_train_all = np.load(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    Y_train_all = np.load(data_path + '/' + 'labels.npy')\n",
    "    #test_all = np.load(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    print('Finish')\n",
    "    return X_train_all, Y_train_all#, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data have already processed\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "X_train_all, Y_train_all = data_preprocessing(data_path, resize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10)\n",
      "(32, 32, 3)\n",
      "bird\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train_all.shape, Y_train_all.shape)\n",
    "sample_id = 6\n",
    "sample_x = X_train_all[sample_id]\n",
    "print(X_train_all[sample_id].shape)\n",
    "print(int2lable[np.argmax(Y_train_all[sample_id], axis=0)])\n",
    "plt.title('train sample', size=16)\n",
    "plt.imshow(sample_x[..., 0])\n",
    "print(X_train_all.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 32, 32, 3) (1000, 32, 32, 3)\n",
      "(10,)\n",
      "[[0.99607843 1.         0.99215686 ... 0.87058824 0.7647059  0.8627451 ]\n",
      " [0.99607843 0.99607843 0.99607843 ... 0.78039217 0.9137255  0.8       ]\n",
      " [0.9607843  0.99215686 0.98039216 ... 0.95686275 0.972549   0.95686275]\n",
      " ...\n",
      " [0.07843138 0.13725491 0.11372549 ... 0.7411765  0.92156863 0.72156864]\n",
      " [0.05098039 0.15686275 0.24705882 ... 0.84313726 0.8117647  0.6156863 ]\n",
      " [0.58431375 0.23529412 0.3019608  ... 0.9098039  0.78431374 0.6901961 ]]\n"
     ]
    }
   ],
   "source": [
    "### 划分验证集 ###\n",
    "#打乱顺序\n",
    "num_example=X_train_all.shape[0]\n",
    "arr=np.arange(num_example)\n",
    "np.random.shuffle(arr)\n",
    "X_train_all=X_train_all[arr]\n",
    "Y_train_all=Y_train_all[arr]\n",
    "\n",
    "VALIDATION_SIZE = 1000    #验证集大小\n",
    "x_val, y_val = X_train_all[:VALIDATION_SIZE], Y_train_all[:VALIDATION_SIZE]\n",
    "x_train, y_train = X_train_all[VALIDATION_SIZE:], Y_train_all[VALIDATION_SIZE:]\n",
    "print(x_train.shape, x_val.shape)\n",
    "print(y_val[0].shape)\n",
    "print(x_train[5][..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_augment(data):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(percent=0.01), # # 从每侧裁剪图像0到16px（随机选择）\n",
    "        iaa.Fliplr(0.5), # 水平翻转图像 括号内为Probability of each image to get flipped.\n",
    "        iaa.Flipud(0.5), #上下翻转\n",
    "        #iaa.GaussianBlur(sigma=(0, 3.0)),  # 使用0到3.0的sigma模糊图像\n",
    "        iaa.Affine(scale=(0.7, 1.3), translate_percent=0.01, rotate=iap.Normal(-10, 10)),#旋转\n",
    "        iaa.Multiply(iap.Positive(iap.Normal(0.0, 0.1)) + 1.0),#明暗变化\n",
    "        #iaa.AddElementwise(iap.Discretize((iap.Beta(0.5, 0.5) * 2 - 1.0) * 64))\n",
    "        #iaa.AdditiveGaussianNoise(scale=(0,  0.05*255)),\n",
    "        iaa.Sharpen(alpha=0.5),\n",
    "        #iaa.Scale((0.5, 1.5))\n",
    "    ],random_order=True)#每个batch中的Augmenters顺序不一样\n",
    "    x_batch = seq.augment_images(data)\n",
    "    return x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示数据扩增后的效果\n",
    "imglist = []\n",
    "#img = imread('data/train/3006.Bmp', as_grey=True)\n",
    "sample_id = 6\n",
    "sample_x = X_train_all[sample_id]\n",
    "#img = cv2.imread('data/train/2212.Bmp', 0)\n",
    "#plt.subplot(2, 10, 1)\n",
    "plt.imshow(sample_x)\n",
    "plt.show()\n",
    "imglist.append(sample_x)\n",
    "for i in range(10):\n",
    "    images_aug = seq.augment_images(imglist)\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(images_aug[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型 lenet\n",
    "def LeNet_5(x, classnum):\n",
    "    with tf.name_scope('layer1-conv'):\n",
    "        conv1 = tf.layers.conv2d(x, 6, 5, strides=1, padding='VALID')\n",
    "        relu1 = tf.nn.relu(conv1)\n",
    "    with tf.name_scope('layer2-pool'):\n",
    "        pool2 = tf.layers.max_pooling2d(relu1, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.name_scope('layer3-conv'):\n",
    "        conv3 = tf.layers.conv2d(pool2, 16, 5, strides=1, padding='VALID')\n",
    "        relu3 = tf.nn.relu(conv3)\n",
    "    with tf.name_scope('layer4-pool'):\n",
    "        pool4 = tf.layers.max_pooling2d(relu3, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.name_scope('layer5-FC'):\n",
    "        flatten = tf.reshape(pool4, [-1, 5*5*16])\n",
    "        fc5 = tf.layers.dense(flatten, 120)\n",
    "        relu5 = tf.nn.relu(fc5)\n",
    "    with tf.name_scope('layer6-fc'):\n",
    "        fc6 = tf.layers.dense(relu5, 84)\n",
    "        relu6 = tf.nn.relu(fc6)\n",
    "    with tf.name_scope('layer7-fc'):\n",
    "        output = tf.layers.dense(relu6, classnum)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss is 1.329217 validataion loss is 1.609813 accuracy is 0.413000\n",
      "----epoch 0 current best_validation_loss is 1.609813\n",
      "epoch 5 train loss is 1.185284 validataion loss is 1.199822 accuracy is 0.584000\n",
      "----epoch 5 current best_validation_loss is 1.199822\n",
      "epoch 10 train loss is 0.964852 validataion loss is 1.135758 accuracy is 0.601000\n",
      "----epoch 10 current best_validation_loss is 1.135758\n",
      "epoch 15 train loss is 1.008341 validataion loss is 1.075241 accuracy is 0.626000\n",
      "----epoch 15 current best_validation_loss is 1.075241\n",
      "epoch 20 train loss is 0.867024 validataion loss is 1.123864 accuracy is 0.630000\n",
      "epoch 25 train loss is 0.912986 validataion loss is 1.081080 accuracy is 0.627000\n",
      "epoch 30 train loss is 0.856833 validataion loss is 1.080944 accuracy is 0.634000\n",
      "epoch 35 train loss is 0.859973 validataion loss is 1.066296 accuracy is 0.644000\n",
      "----epoch 35 current best_validation_loss is 1.066296\n",
      "epoch 40 train loss is 0.696139 validataion loss is 1.047598 accuracy is 0.649000\n",
      "----epoch 40 current best_validation_loss is 1.047598\n",
      "epoch 45 train loss is 0.669434 validataion loss is 1.115492 accuracy is 0.646000\n",
      "epoch 50 train loss is 0.785772 validataion loss is 1.102635 accuracy is 0.668000\n",
      "epoch 55 train loss is 0.479241 validataion loss is 1.107932 accuracy is 0.648000\n",
      "epoch 60 train loss is 0.610799 validataion loss is 1.121498 accuracy is 0.646000\n",
      "epoch 65 train loss is 0.527614 validataion loss is 1.097533 accuracy is 0.652000\n",
      "epoch 70 train loss is 0.570460 validataion loss is 1.229966 accuracy is 0.641000\n",
      "epoch 75 train loss is 0.468933 validataion loss is 1.153389 accuracy is 0.651000\n",
      "epoch 80 train loss is 0.832506 validataion loss is 1.250992 accuracy is 0.656000\n",
      "epoch 85 train loss is 0.282114 validataion loss is 1.236124 accuracy is 0.655000\n",
      "epoch 90 train loss is 0.465886 validataion loss is 1.187174 accuracy is 0.655000\n",
      "epoch 95 train loss is 0.381178 validataion loss is 1.312572 accuracy is 0.656000\n",
      "epoch 100 train loss is 0.558865 validataion loss is 1.383747 accuracy is 0.641000\n",
      "epoch 105 train loss is 0.348993 validataion loss is 1.388216 accuracy is 0.643000\n",
      "epoch 110 train loss is 0.456292 validataion loss is 1.429181 accuracy is 0.643000\n",
      "epoch 115 train loss is 0.386060 validataion loss is 1.458549 accuracy is 0.633000\n",
      "epoch 120 train loss is 0.394234 validataion loss is 1.411315 accuracy is 0.641000\n",
      "epoch 125 train loss is 0.372055 validataion loss is 1.502838 accuracy is 0.636000\n",
      "epoch 130 train loss is 0.395287 validataion loss is 1.525083 accuracy is 0.648000\n",
      "epoch 135 train loss is 0.288133 validataion loss is 1.647910 accuracy is 0.638000\n",
      "epoch 140 train loss is 0.293804 validataion loss is 1.568848 accuracy is 0.649000\n",
      "early stoping\n"
     ]
    }
   ],
   "source": [
    "### 训练 ###\n",
    "### 训练 ###\n",
    "#训练参数\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500             #迭代次数\n",
    "EARLY_STOP_PATIENCE = 100 #控制early stopping的参数\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_data = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y_data = tf.placeholder(tf.float32, [None, 10])\n",
    "ckpt_path = './model/lenet/mode.ckpt'\n",
    "\n",
    "predict = LeNet_5(x_data, 10)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=y_data))\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):#批归一化层\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(predict, 1), tf.argmax(y_data, 1)), tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    best_validation_loss = 1000000.0\n",
    "    current_epoch = 0\n",
    "    \n",
    "    epoch = EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    train_size = len(x_train)\n",
    "    train_index = list(range(train_size))\n",
    "    for n in range(epoch):\n",
    "        random.shuffle(train_index)  # 每个epoch都shuffle一下效果更好\n",
    "        x_train_, y_train_ = x_train[train_index], y_train[train_index]\n",
    "        #添加交叉验证\n",
    "        #x_train, x_val, y_train, y_val = train_test_split(train_img, train_y, test_size=0.1, random_state=42, shuffle=True)\n",
    "        for i in range(0, train_size, batch_size):\n",
    "            x_batch = x_train_[i : i + batch_size]\n",
    "            y_batch = y_train_[i : i + batch_size]\n",
    "            _, loss_step = sess.run([train_step, loss], \\\n",
    "                             feed_dict={x_data:x_batch, y_data:y_batch})\n",
    "            #数据扩充\n",
    "            x_batch_aug = batch_augment(x_batch)\n",
    "            _, loss_aug = sess.run([train_step, loss], \\\n",
    "                                    feed_dict={x_data:x_batch_aug, y_data:y_batch})\n",
    "        if n % 5 == 0:\n",
    "            validation_loss, accuracy = sess.run([loss, acc], feed_dict={x_data:x_val, y_data:y_val})\n",
    "            #validation_loss = loss.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            #accuracy = acc.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            print(\"epoch %d train loss is %f validataion loss is %f accuracy is %f\" % (n, loss_step, validation_loss, accuracy))\n",
    "        if validation_loss < best_validation_loss:\n",
    "            print('----  epoch %d current best_validation_loss is %f' % (n, validation_loss))\n",
    "            best_validation_loss = validation_loss\n",
    "            current_epoch = n\n",
    "            saver.save(sess, ckpt_path)\n",
    "        elif (n - current_epoch) >= EARLY_STOP_PATIENCE:\n",
    "            print('early stoping')\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 计算混淆矩阵  ###\n",
    "def testModel(ckpt_path):\n",
    "    tf.reset_default_graph()#mo\n",
    "    x_data = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    y_data = tf.placeholder(tf.float32, [None, 10])\n",
    "    out = LeNet_5(x_data, 10)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1), tf.argmax(y_data, 1)), tf.float32))\n",
    "    saver = tf.train.Saver() \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, ckpt_path)\n",
    "        #sess.run(out, feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "        y_hat = out.eval({x_data: x_val})\n",
    "        y_pred = np.argmax(y_hat, axis=1)\n",
    "        y_true = np.argmax(y_val, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        '''\n",
    "        for i in range(cm.shape[0]):# 混淆矩阵\n",
    "            for j in range(cm.shape[1]):\n",
    "                print(cm[i][j], end=' ')\n",
    "            print('\\n')\n",
    "        '''\n",
    "        print(cm)\n",
    "        acc = accuracy.eval(feed_dict={x_data:x_val, y_data:y_val})\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/lenet/mode.ckpt\n",
      "[[64  4  4  4  5  0  0  0  6  5]\n",
      " [ 8 76  0  0  1  0  2  0  4 10]\n",
      " [ 5  1 45  7 19  6  3  6  3  2]\n",
      " [ 7  2  6 42  6 20  6 10  3  2]\n",
      " [ 1  2  4  4 64  3  4  8  0  2]\n",
      " [ 2  0  6 19  7 76  1 10  0  0]\n",
      " [ 3  2  4  7 14  4 50  1  1  3]\n",
      " [ 3  1  3  7 12 11  1 61  1  1]\n",
      " [12  1  2  3  2  0  0  0 77  3]\n",
      " [ 2 13  0  5  0  1  0  3  3 76]]\n",
      "0.631\n"
     ]
    }
   ],
   "source": [
    "testModel(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试数据读取\n",
    "def test_data_preprocessing(data_path, resize=True, img_rows=32, img_cols=32):\n",
    "    if (os.path.exists(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy')):\n",
    "        print('data have already processed')\n",
    "    else:\n",
    "        ### Image preprocessing ###\n",
    "        if resize == True:\n",
    "            if not os.path.exists(data_path + \"/testResized\"):\n",
    "                os.makedirs(data_path + \"/'dtestResized\")\n",
    "        for set_type in ['test']:\n",
    "            files = natsorted(glob.glob(data_path + '/' + set_type + '/*'))\n",
    "            data = np.zeros((len(files), img_rows, img_cols, 3))\n",
    "            for i, file_path in enumerate(files):\n",
    "                '''\n",
    "                img = imread(file_path, as_grey=True) #读入的图为[0, 1]图\n",
    "                img_resized = resize(img, (img_rows, img_cols))\n",
    "                data[i] = img_resized\n",
    "                #Save image\n",
    "                new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                imsave(new_name, img_resized)\n",
    "                '''\n",
    "                #利用opencv读取图片\n",
    "                img = cv2.imread(file_path) #读入彩色图\n",
    "                if resize == True:\n",
    "                    img_resized = cv2.resize(img, (img_rows, img_cols))#读入的[0, 255]的图\n",
    "                    data[i] = img_resized\n",
    "                    #Save image\n",
    "                    new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                    cv2.imwrite(new_name, img_resized) \n",
    "                else:\n",
    "                    data[i] = img\n",
    "            #Add channel/filter dimension [222, 32, 32] => [222, 1, 32, 32]\n",
    "            #train_img = np.stack(train_img)[..., None]\n",
    "            #data = data[:, :, :, np.newaxis]\n",
    "            data = data.astype('float32')\n",
    "            data /= 255\n",
    "            np.save(data_path + '/' + set_type + '_' + str(img_rows) +  '_' + str(img_cols) + '.npy', data)\n",
    "    test_all = np.load(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    print('Finish')\n",
    "    return test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data have already processed\n",
      "Finish\n",
      "(300000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "test_all = test_data_preprocessing(data_path, resize=False)\n",
    "print(test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Submit ###\n",
    "def submit(model_save_path, output_file):\n",
    "    tf.reset_default_graph()\n",
    "    x_test_data = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    logits = LeNet_5(x_test_data, 10)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, model_save_path)\n",
    "        \n",
    "        test_size = len(test_all)\n",
    "        print(test_size)\n",
    "        batch_size = 200\n",
    "        f = open(output_file, 'w')\n",
    "        f.write('id,label\\n')\n",
    "        for i in range(0, test_size, batch_size):\n",
    "            x_test_batch = test_all[i : i + batch_size]\n",
    "            y_hat = logits.eval({x_test_data: x_test_batch})\n",
    "            y_pred_batch = np.argmax(y_hat, axis=1)\n",
    "            #vInt2label = np.vectorize(int2label)\n",
    "            #print(len(x_test_batch))\n",
    "            for i in range(len(y_pred_batch)):\n",
    "                #print(i)\n",
    "                f.write(\"\".join([str(i+1), ',', int2lable[y_pred_batch[i]], '\\n']))\n",
    "        f.close()\n",
    "    print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/lenet/mode.ckpt\n",
      "300000\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "output_file = \"submission.csv\"\n",
    "submit(ckpt_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
