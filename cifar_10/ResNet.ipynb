{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from progressbar import * #进度条\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imsave\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import transform, filters, exposure\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于数据集较大，采用tensorflow自带的TFRecord进行读取\n",
    "def Trainset2TFRecord2(train_tfrecords_path, val_tfrecords_path, ratio=0.9, data_path='data'):\n",
    "    files = natsorted(glob.glob(data_path + '/train/*'))\n",
    "    total = len(files)\n",
    "    train_num = int(total*ratio)\n",
    "    val_num = total-train_num\n",
    "    if (os.path.exists(train_tfrecords_path) and os.path.exists(val_tfrecords_path)):\n",
    "        print('data have already processed')\n",
    "        return train_num, val_num\n",
    "    \n",
    "    writer_train = tf.python_io.TFRecordWriter(train_tfrecords_path)\n",
    "    writer_val = tf.python_io.TFRecordWriter(val_tfrecords_path)\n",
    "    \n",
    "    labels = pd.read_csv(data_path + '/trainLabels.csv')\n",
    "    \n",
    "    pbar = ProgressBar().start()\n",
    "    for i, file_path in enumerate(files):\n",
    "        pbar.update(int((i / (total - 1)) * 100))#进度条\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        img_raw = tf.gfile.FastGFile(file_path, 'rb').read()\n",
    "        label = label2int[labels.loc[i].label]\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "        }))\n",
    "        if i < train_num:\n",
    "            writer_train.write(example.SerializeToString())\n",
    "        else:\n",
    "            writer_val.write(example.SerializeToString())\n",
    "    writer_train.close()\n",
    "    writer_val.close()\n",
    "    pbar.finish()\n",
    "    \n",
    "    return train_num, val_num\n",
    "def TFRecord2TrainData2(train_tfrecords_path, num_class, batch_size, num_epochs, shuffle=True):\n",
    "    filename_queue = tf.train.string_input_producer([train_tfrecords_path], num_epochs=num_epochs)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                       'img_raw' : tf.FixedLenFeature([], tf.string),\n",
    "                                       'label': tf.FixedLenFeature([], tf.int64)\n",
    "                                   })\n",
    "    img = tf.image.decode_png(features['img_raw'])  # 与方式一的不同点在于需要用decode_png/decode_jpeg解码\n",
    "                                                    # output an RGB image. [height, width, channels]\n",
    "    img = tf.reshape(img, [32, 32, 3])\n",
    "    img = tf.image.resize_images(img, [224, 224])\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label = tf.one_hot(label,num_class,1,0)\n",
    "    if shuffle==True:\n",
    "        img_batch, label_batch = tf.train.shuffle_batch([img, label], batch_size=batch_size,\\\n",
    "                                                        capacity=500 + 3 * batch_size, min_after_dequeue=500)\n",
    "    else:\n",
    "        img_batch, label_batch = tf.train.batch([img, label], batch_size=batch_size, capacity= 3 * batch_size)\n",
    "    return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data have already processed\n",
      "45000 5000\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords_path = 'data/train.tfrecord'\n",
    "val_tfrecords_path = 'data/val.tfrecord'\n",
    "train_num, val_num = Trainset2TFRecord2(train_tfrecords_path, val_tfrecords_path)\n",
    "print(train_num, val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0 (128, 224, 224, 3)\n",
      "val\n",
      "0 (128, 224, 224, 3)\n",
      "train\n",
      "1 (128, 224, 224, 3)\n",
      "val\n",
      "1 (128, 224, 224, 3)\n",
      "train\n",
      "2 (128, 224, 224, 3)\n",
      "val\n",
      "2 (128, 224, 224, 3)\n",
      "train\n",
      "3 (128, 224, 224, 3)\n",
      "val\n",
      "3 (128, 224, 224, 3)\n",
      "train\n",
      "4 (128, 224, 224, 3)\n",
      "val\n",
      "4 (128, 224, 224, 3)\n",
      "train\n",
      "5 (128, 224, 224, 3)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#解码并查看效果\n",
    "#img,label = TFRecord2TrainData(train_tfrecords_path, 10)\n",
    "#img_batch, label_batch = tf.train.shuffle_batch([img, label], batch_size=500, capacity=50000, min_after_dequeue=1000, num_threads=1)\n",
    "#capacity是队列的最大容量, min_after_dequeue是dequeue后最小的队列大小,这个代表队列中的元素大于它的时候就输出乱的顺序的batch\n",
    "#num_threads是进行队列操作的线程数。\n",
    "img_train_batch, label_train_batch = TFRecord2TrainData2(train_tfrecords_path, 10, 128, 5)\n",
    "img_val_batch, label_val_batch = TFRecord2TrainData2(val_tfrecords_path, 10, 128, 5)#10类 batch_size=128, epoch = 5\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    #先产生！个看下效果\n",
    "    '''\n",
    "    for epoch in range(10):\n",
    "        try:\n",
    "            while not coord.should_stop():\n",
    "                img_, label_ = sess.run([img_batch, label_batch]) \n",
    "                print(epoch)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"done\")\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    ''' \n",
    "    #验证集上测试\n",
    "    try:\n",
    "        train_total_batch = int(train_num/128)\n",
    "        val_total_bath = int(val_num/128)\n",
    "        epoch = 0\n",
    "        while not coord.should_stop():#使用 coord.should_stop()来查询是否应该终止所有线程\n",
    "            #开始一个epoch的训练\n",
    "            train_begin = 0\n",
    "            val_begin = 0\n",
    "            for i in range(train_total_batch):\n",
    "                img_, label_ = sess.run([img_train_batch, label_train_batch]) \n",
    "                if train_begin == 0:\n",
    "                    print(\"train\")\n",
    "                    print(epoch, img_.shape)\n",
    "                    train_begin = 1\n",
    "            for i in range(val_total_bath):\n",
    "                img_, label_ = sess.run([img_val_batch, label_val_batch]) \n",
    "                if val_begin == 0:\n",
    "                    print(\"val\")\n",
    "                    print(epoch, img_.shape)\n",
    "                    val_begin = 1\n",
    "            epoch+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"done\")\n",
    "    finally:       \n",
    "        coord.request_stop()#使用coord.request_stop()来发出终止所有线程的命令\n",
    "        coord.join(threads)#使用coord.join(threads)把线程加入主线程，等待threads结束。\n",
    "    '''\n",
    "    for i in range(10): #产生10个batch\n",
    "        img_, label_ = sess.run([img_batch, label_batch])#每次输出queue中的一个batch\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        label = int2lable[np.argmax(label_, axis=1)[0]]\n",
    "        plt.title(label)\n",
    "        plt.imshow(img_[0].astype('uint8'))\n",
    "        i += 1\n",
    "    plt.show()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_augment(data):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(percent=0.01), # # 从每侧裁剪图像0到16px（随机选择）\n",
    "        iaa.Fliplr(0.5), # 水平翻转图像 括号内为Probability of each image to get flipped.\n",
    "        iaa.Flipud(0.5), #上下翻转\n",
    "        #iaa.GaussianBlur(sigma=(0, 3.0)),  # 使用0到3.0的sigma模糊图像\n",
    "        iaa.Affine(scale=(0.7, 1.3), translate_percent=0.01, rotate=iap.Normal(-20, 20)),#旋转\n",
    "        iaa.Multiply(iap.Positive(iap.Normal(0.0, 0.1)) + 1.0),#明暗变化\n",
    "        #iaa.AddElementwise(iap.Discretize((iap.Beta(0.5, 0.5) * 2 - 1.0) * 64))\n",
    "        #iaa.AdditiveGaussianNoise(scale=(0,  0.05*255)),\n",
    "        #iaa.Sharpen(alpha=0.5),\n",
    "        #iaa.Scale((0.5, 1.5))\n",
    "    ],random_order=True)#每个batch中的Augmenters顺序不一样\n",
    "    x_batch = seq.augment_images(data)\n",
    "    return x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "img_train_batch, label_train_batch = TFRecord2TrainData2(train_tfrecords_path, 10, batch_size, 1)\n",
    "img_val_batch, label_val_batch = TFRecord2TrainData2(val_tfrecords_path, 10, batch_size, 1)#10类 batch_size=128, epoch = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    for i in range(1) : #产生1个batch\n",
    "        img_batch, label_batch = sess.run([img_train_batch, label_train_batch])#每次输出queue中的一个batch\n",
    "        for j in range(batch_size):\n",
    "            plt.subplot(2, batch_size, j+1)\n",
    "            label = int2lable[np.argmax(label_batch, axis=1)[j]]\n",
    "            plt.title(label)\n",
    "            plt.imshow(img_batch[j].astype('uint8'))\n",
    "        #扩增后的数据\n",
    "        '''\n",
    "        for j in range(batch_size):\n",
    "            plt.subplot(2, batch_size, j+batch_size+1)\n",
    "            label = int2lable[np.argmax(label_batch, axis=1)[j]]\n",
    "            plt.title(label)\n",
    "            plt.imshow(img_batch[j].astype('uint8'))\n",
    "        '''\n",
    "        img_aug = batch_augment(img_batch)\n",
    "        for j in range(batch_size):\n",
    "            plt.subplot(2, batch_size, j+batch_size+1)\n",
    "            label = int2lable[np.argmax(label_batch, axis=1)[j]]\n",
    "            plt.title(label)\n",
    "            plt.imshow(img_aug[j].astype('uint8'))\n",
    "        \n",
    "    plt.show()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 查看预训练模型中的参数 ###\n",
    "ckpt_path = './model/vgg19/mode.ckpt'\n",
    "pre_model_path = 'model/vgg19/vgg19.npy'\n",
    "pre_model = np.load(pre_model_path, encoding = \"bytes\").item()\n",
    "layers = list(pre_model.keys())#将dict转换为list  层的名称\n",
    "#layer_1 = pre_model[layers[0]] #第一层中内容\n",
    "#layer_1_w =  pre_model[layers[0]][0]  #第一层的权重\n",
    "print(layers)\n",
    "layer_1_0 =  pre_model[layers[0]][1] #第一层的偏差\n",
    "print(pre_model[layers[0]][0].shape) #第一层权重的形状 (3, 3, 3, 64)\n",
    "print(pre_model[layers[0]][1].shape) #第一层的偏差的形状 (64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
