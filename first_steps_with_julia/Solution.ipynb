{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhw/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/lhw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imsave\n",
    "from sklearn.metrics import confusion_matrix\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "%matplotlib inline\n",
    "#http://ankivil.com/kaggle-first-steps-with-julia-chars74k-first-place-using-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2int(ch):\n",
    "    ascii_val = ord(ch)\n",
    "    if(ascii_val <= 57): #0-9\n",
    "        ascii_val -= 48\n",
    "    elif(ascii_val <= 90): #A-Z\n",
    "        ascii_val -= 55\n",
    "    else: #a-z\n",
    "        ascii_val -= 61\n",
    "    return ascii_val\n",
    "def int2label(i):\n",
    "    if(i <= 9): #0-9\n",
    "        i += 48\n",
    "    elif(i<=35): #A-Z\n",
    "        i += 55\n",
    "    else: #a-z\n",
    "        i += 61\n",
    "    return chr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片数据持久化，保存到本地，供下次直接调用\n",
    "def data_preprocessing(data_path, img_rows=32, img_cols=32):\n",
    "    if (os.path.exists(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        and os.path.exists(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        and os.path.exists(data_path + '/' + 'labels.npy')):\n",
    "        print('data have already processed')\n",
    "    else:\n",
    "        ### Image preprocessing ###\n",
    "        if not os.path.exists(data_path + \"/trainResized\"):\n",
    "            os.makedirs(data_path + \"/trainResized\")\n",
    "        if not os.path.exists(data_path + \"/testResized\"):\n",
    "            os.makedirs(data_path + \"/testResized\")\n",
    "        for set_type in ['train', 'test']:\n",
    "            files = natsorted(glob.glob(data_path + '/' + set_type + '/*'))\n",
    "            data = np.zeros((len(files), img_rows, img_cols))\n",
    "            for i, file_path in enumerate(files):\n",
    "                img = imread(file_path, as_grey=True) #读入的图为[0, 1]图\n",
    "                img_resized = resize(img, (img_rows, img_cols))\n",
    "                data[i] = img_resized\n",
    "                #Save image\n",
    "                new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                imsave(new_name, img_resized)\n",
    "            #Add channel/filter dimension [222, 32, 32] => [222, 1, 32, 32]\n",
    "            #train_img = np.stack(train_img)[..., None]\n",
    "            data = data[:, :, :, np.newaxis]\n",
    "            data = data.astype('float32')\n",
    "            #data /= 255\n",
    "            np.save(data_path + '/' + set_type + '_' + str(img_rows) +  '_' + str(img_cols) + '.npy', data)\n",
    "        ### Labels preprocessing ###\n",
    "        y_train = pd.read_csv(data_path + '/trainLabels.csv').values[:, 1]\n",
    "        #Convert one-hot vectors\n",
    "        Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    "        for i in range(y_train.shape[0]):\n",
    "            Y_train[i][label2int(y_train[i])] = 1\n",
    "        np.save(data_path + '/' + 'labels.npy', Y_train)\n",
    "    X_train_all = np.load(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    Y_train_all = np.load(data_path + '/' + 'labels.npy')\n",
    "    test_all = np.load(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    print('Finish')\n",
    "    return X_train_all, Y_train_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data have already processed\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "X_train_all, Y_train_all, test_all = data_preprocessing(data_path, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6283, 32, 32, 1) (6283, 62) (6220, 32, 32, 1)\n",
      "(32, 32, 1)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30b7cf02e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train_all.shape, Y_train_all.shape, test_all.shape)\n",
    "sample_x = X_train_all[5]\n",
    "print(X_train_all[5].shape)\n",
    "print(Y_train_all[5])\n",
    "plt.title('train sample', size=16)\n",
    "plt.imshow(sample_x[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6083, 32, 32, 1) (200, 32, 32, 1)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "### 划分验证集 ###\n",
    "#数据预处理 方法二\n",
    "VALIDATION_SIZE = 200    #验证集大小\n",
    "x_val, y_val = X_train_all[:VALIDATION_SIZE], Y_train_all[:VALIDATION_SIZE]\n",
    "x_train, y_train = X_train_all[VALIDATION_SIZE:], Y_train_all[VALIDATION_SIZE:]\n",
    "print(x_train.shape, x_val.shape)\n",
    "print(y_val[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###定义模型###\n",
    "def model(x, classes, is_training):\n",
    "    with tf.variable_scope('layer1-conv'):\n",
    "        conv1 = tf.layers.conv2d(x, 128, 3, strides=1, padding='SAME')\n",
    "        norm1 = tf.layers.batch_normalization(conv1, center=True, scale=True, training=is_training)\n",
    "        relu1 = tf.nn.relu(norm1)\n",
    "    with tf.variable_scope('layer2-conv-pool'):\n",
    "        conv2 = tf.layers.conv2d(relu1, 128, 3, strides=1, padding='SAME')\n",
    "        norm2 = tf.layers.batch_normalization(conv2, center=True, scale=True, training=is_training)\n",
    "        relu2 = tf.nn.relu(norm2)\n",
    "        pool2 = tf.layers.max_pooling2d(relu2, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer3-conv'):\n",
    "        conv3 = tf.layers.conv2d(pool2, 256, 3, strides=1, padding='SAME')\n",
    "        norm3 = tf.layers.batch_normalization(conv3, center=True, scale=True, training=is_training)\n",
    "        relu3 = tf.nn.relu(norm3)\n",
    "    with tf.variable_scope('layer4-conv-pool'):\n",
    "        conv4 = tf.layers.conv2d(relu3, 256, 3, strides=1, padding='SAME')\n",
    "        norm4 = tf.layers.batch_normalization(conv4, center=True, scale=True, training=is_training)\n",
    "        relu4 = tf.nn.relu(norm4)\n",
    "        pool4 = tf.layers.max_pooling2d(relu4, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer5-conv'):\n",
    "        conv5 = tf.layers.conv2d(pool4, 512, 3, strides=1, padding='SAME')\n",
    "        norm5 = tf.layers.batch_normalization(conv5, center=True, scale=True, training=is_training)\n",
    "        relu5 = tf.nn.relu(norm5)\n",
    "    with tf.variable_scope('layer6-conv'):\n",
    "        conv6 = tf.layers.conv2d(relu5, 512, 3, strides=1, padding='SAME')\n",
    "        norm6 = tf.layers.batch_normalization(conv6, center=True, scale=True, training=is_training)\n",
    "        relu6 = tf.nn.relu(norm6) \n",
    "    with tf.variable_scope('layer7-conv-pool'):\n",
    "        conv7 = tf.layers.conv2d(relu6, 512, 3, strides=1, padding='SAME')\n",
    "        norm7 = tf.layers.batch_normalization(conv7, center=True, scale=True, training=is_training)\n",
    "        relu7 = tf.nn.relu(norm7)\n",
    "        pool7 = tf.layers.max_pooling2d(relu7, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer8-FC'):\n",
    "        flatten = tf.reshape(pool7, [-1, 4*4*512])\n",
    "        affine8 = tf.layers.dense(flatten, 4096)\n",
    "        norm8 = tf.layers.batch_normalization(affine8, center=True, scale=True, training=is_training)\n",
    "        relu8 = tf.nn.relu(norm8)\n",
    "        if is_training == True:\n",
    "            relu8 = tf.layers.dropout(relu8, 0.5)   \n",
    "    with tf.variable_scope('layer9-FC'):\n",
    "        affine9 = tf.layers.dense(relu8, 4096)\n",
    "        norm9 = tf.layers.batch_normalization(affine9, center=True, scale=True, training=is_training)\n",
    "        relu9 = tf.nn.relu(norm9)\n",
    "        if is_training == True:\n",
    "            relu9 = tf.layers.dropout(relu9, 0.5)\n",
    "    with tf.variable_scope('layer10-FC'):\n",
    "        output = tf.layers.dense(relu9, classes)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss is 3.481383 validataion loss is 48.421124\n",
      "epoch 5 train loss is 0.774207 validataion loss is 2.018104\n",
      "epoch 10 train loss is 0.244901 validataion loss is 1.319927\n",
      "epoch 15 train loss is 0.087827 validataion loss is 1.340053\n",
      "epoch 20 train loss is 0.121914 validataion loss is 1.553443\n",
      "epoch 25 train loss is 0.247994 validataion loss is 1.715017\n",
      "epoch 30 train loss is 0.019208 validataion loss is 1.698038\n",
      "epoch 35 train loss is 0.037844 validataion loss is 2.254268\n",
      "epoch 40 train loss is 0.018411 validataion loss is 1.798746\n",
      "epoch 45 train loss is 0.112877 validataion loss is 1.908942\n",
      "epoch 50 train loss is 0.039583 validataion loss is 1.935814\n",
      "epoch 55 train loss is 0.077879 validataion loss is 1.719483\n",
      "epoch 60 train loss is 0.016703 validataion loss is 1.678846\n",
      "epoch 65 train loss is 0.000784 validataion loss is 1.385618\n",
      "epoch 70 train loss is 0.000255 validataion loss is 1.403576\n",
      "epoch 75 train loss is 0.000041 validataion loss is 1.424350\n",
      "epoch 80 train loss is 0.000548 validataion loss is 1.439452\n",
      "epoch 85 train loss is 0.000044 validataion loss is 1.452702\n",
      "epoch 90 train loss is 0.000032 validataion loss is 1.465797\n",
      "epoch 95 train loss is 0.000012 validataion loss is 1.471208\n",
      "epoch 100 train loss is 0.000027 validataion loss is 1.481421\n",
      "epoch 105 train loss is 0.000042 validataion loss is 1.490267\n",
      "epoch 110 train loss is 0.000013 validataion loss is 1.501269\n",
      "early stoping\n"
     ]
    }
   ],
   "source": [
    "### 训练 ###\n",
    "#训练参数\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500             #迭代次数\n",
    "EARLY_STOP_PATIENCE = 100 #控制early stopping的参数\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "y_data = tf.placeholder(tf.float32, [None, 62])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "ckpt_path = './model/mode.ckpt'\n",
    "\n",
    "predict = model(x_data, 62, is_training)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=y_data))\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    best_validation_loss = 1000000.0\n",
    "    current_epoch = 0\n",
    "    \n",
    "    epoch = EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    train_size = len(x_train)\n",
    "    train_index = list(range(train_size))\n",
    "    for n in range(epoch):\n",
    "        random.shuffle(train_index)  # 每个epoch都shuffle一下效果更好\n",
    "        x_train_, y_train_ = x_train[train_index], y_train[train_index]\n",
    "        #添加交叉验证\n",
    "        #x_train, x_val, y_train, y_val = train_test_split(train_img, train_y, test_size=0.1, random_state=42, shuffle=True)\n",
    "        for i in range(0, train_size, batch_size):\n",
    "            x_batch = x_train_[i : i + batch_size]\n",
    "            y_batch = y_train_[i : i + batch_size]\n",
    "            _, loss_step = sess.run([train_step, loss], \\\n",
    "                             feed_dict={x_data:x_batch, y_data:y_batch, is_training:True})\n",
    "        if n % 5 == 0:\n",
    "            validation_loss = loss.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            print(\"epoch %d train loss is %f validataion loss is %f\" % (n, loss_step, validation_loss))\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            current_epoch = n\n",
    "            saver.save(sess, ckpt_path)\n",
    "        elif (n - current_epoch) >= EARLY_STOP_PATIENCE:\n",
    "            print('early stoping')\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 计算混淆矩阵  ###\n",
    "def testModel(ckpt_path):\n",
    "    tf.reset_default_graph()#mo\n",
    "    x_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "    y_data = tf.placeholder(tf.float32, [None, 62])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    out = model(x_data, 62, is_training)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1), tf.argmax(y_data, 1)), tf.float32))\n",
    "    saver = tf.train.Saver() \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, ckpt_path)\n",
    "        #sess.run(out, feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "        y_hat = out.eval({x_data: x_val, is_training:False})\n",
    "        y_pred = np.argmax(y_hat, axis=1)\n",
    "        y_true = np.argmax(y_val, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        '''\n",
    "        for i in range(cm.shape[0]):# 混淆矩阵\n",
    "            for j in range(cm.shape[1]):\n",
    "                print(cm[i][j], end=' ')\n",
    "            print('\\n')\n",
    "        '''\n",
    "        print(cm)\n",
    "        acc = accuracy.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mode.ckpt\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"./model/mode.ckpt\"\n",
    "testModel(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Submit ###\n",
    "def submit(model_save_path, output_file):\n",
    "    tf.reset_default_graph()\n",
    "    x_test_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    logits = model(x_test_data, 62, is_training)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, model_save_path)\n",
    "        \n",
    "        y_pred = []\n",
    "        test_size = len(test_all)\n",
    "        batch_size = 1\n",
    "        for i in range(0, test_size, batch_size):\n",
    "            x_test_batch = test_all[i*batch_size : (i+1)*batch_size]\n",
    "            y_hat = logits.eval({x_test_data: x_test_batch, is_training:False})\n",
    "            y_pred_batch = np.argmax(y_hat, axis=1)\n",
    "            #vInt2label = np.vectorize(int2label)\n",
    "            y_pred.append(int2label(y_pred_batch))      \n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write('ID,Class\\n')\n",
    "            for i in range(len(y_pred)):\n",
    "                f.write(\"\".join([str(i+6284), ',', y_pred[i], '\\n']))\n",
    "        print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mode.ckpt\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./model/mode.ckpt\"\n",
    "output_file = \"submission.csv\"\n",
    "submit(model_save_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
