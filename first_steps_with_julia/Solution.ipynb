{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imsave\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import transform, filters, exposure\n",
    "from stn import spatial_transformer_network as transformer\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "%matplotlib inline\n",
    "#http://ankivil.com/kaggle-first-steps-with-julia-chars74k-first-place-using-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2int(ch):\n",
    "    ascii_val = ord(ch)\n",
    "    if(ascii_val <= 57): #0-9\n",
    "        ascii_val -= 48\n",
    "    elif(ascii_val <= 90): #A-Z\n",
    "        ascii_val -= 55\n",
    "    else: #a-z\n",
    "        ascii_val -= 61\n",
    "    return ascii_val\n",
    "def int2label(i):\n",
    "    if(i <= 9): #0-9\n",
    "        i += 48\n",
    "    elif(i<=35): #A-Z\n",
    "        i += 55\n",
    "    else: #a-z\n",
    "        i += 61\n",
    "    return chr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片数据持久化，保存到本地，供下次直接调用\n",
    "def data_preprocessing(data_path, img_rows=32, img_cols=32):\n",
    "    if (os.path.exists(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        and os.path.exists(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy') \n",
    "        and os.path.exists(data_path + '/' + 'labels.npy')):\n",
    "        print('data have already processed')\n",
    "    else:\n",
    "        ### Image preprocessing ###\n",
    "        if not os.path.exists(data_path + \"/trainResized\"):\n",
    "            os.makedirs(data_path + \"/trainResized\")\n",
    "        if not os.path.exists(data_path + \"/testResized\"):\n",
    "            os.makedirs(data_path + \"/testResized\")\n",
    "        for set_type in ['train', 'test']:\n",
    "            files = natsorted(glob.glob(data_path + '/' + set_type + '/*'))\n",
    "            data = np.zeros((len(files), img_rows, img_cols))\n",
    "            for i, file_path in enumerate(files):\n",
    "                '''\n",
    "                img = imread(file_path, as_grey=True) #读入的图为[0, 1]图\n",
    "                img_resized = resize(img, (img_rows, img_cols))\n",
    "                data[i] = img_resized\n",
    "                #Save image\n",
    "                new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                imsave(new_name, img_resized)\n",
    "                '''\n",
    "                #利用opencv读取图片\n",
    "                img = cv2.imread(file_path, 0)\n",
    "                img_resized = cv2.resize(img, (img_rows, img_cols))#读入的[0, 255]的图\n",
    "                data[i] = img_resized\n",
    "                #Save image\n",
    "                new_name = \"/\".join(file_path.split(\"/\")[:-1] ) + \"Resized/\" + file_path.split(\"/\")[-1]\n",
    "                cv2.imwrite(new_name, img_resized)                \n",
    "            #Add channel/filter dimension [222, 32, 32] => [222, 1, 32, 32]\n",
    "            #train_img = np.stack(train_img)[..., None]\n",
    "            data = data[:, :, :, np.newaxis]\n",
    "            #data = data.astype('float32')\n",
    "            #data /= 255\n",
    "            np.save(data_path + '/' + set_type + '_' + str(img_rows) +  '_' + str(img_cols) + '.npy', data)\n",
    "        ### Labels preprocessing ###\n",
    "        y_train = pd.read_csv(data_path + '/trainLabels.csv').values[:, 1]\n",
    "        #Convert one-hot vectors\n",
    "        Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    "        for i in range(y_train.shape[0]):\n",
    "            Y_train[i][label2int(y_train[i])] = 1\n",
    "        np.save(data_path + '/' + 'labels.npy', Y_train)\n",
    "    X_train_all = np.load(data_path + '/' + 'train_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    Y_train_all = np.load(data_path + '/' + 'labels.npy')\n",
    "    test_all = np.load(data_path + '/' + 'test_' + str(img_rows) +  '_' + str(img_cols) + '.npy')\n",
    "    print('Finish')\n",
    "    return X_train_all, Y_train_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "X_train_all, Y_train_all, test_all = data_preprocessing(data_path, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6283, 32, 32, 1) (6283, 62) (6220, 32, 32, 1)\n",
      "(32, 32, 1)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train_all.shape, Y_train_all.shape, test_all.shape)\n",
    "sample_x = X_train_all[5]\n",
    "print(X_train_all[5].shape)\n",
    "print(Y_train_all[5])\n",
    "plt.title('train sample', size=16)\n",
    "plt.imshow(sample_x[..., 0])\n",
    "print(X_train_all.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6083, 32, 32, 1) (200, 32, 32, 1)\n",
      "(62,)\n",
      "[[45 46 41 ... 47 40 40]\n",
      " [44 50 58 ... 51 53 46]\n",
      " [52 67 65 ... 43 51 48]\n",
      " ...\n",
      " [46 46 43 ... 45 43 45]\n",
      " [47 43 46 ... 47 47 47]\n",
      " [50 49 44 ... 42 47 46]]\n"
     ]
    }
   ],
   "source": [
    "### 划分验证集 ###\n",
    "#数据预处理 方法二\n",
    "VALIDATION_SIZE = 200    #验证集大小\n",
    "x_val, y_val = X_train_all[:VALIDATION_SIZE], Y_train_all[:VALIDATION_SIZE]\n",
    "x_train, y_train = X_train_all[VALIDATION_SIZE:].astype('uint8'), Y_train_all[VALIDATION_SIZE:].astype('uint8')\n",
    "print(x_train.shape, x_val.shape)\n",
    "print(y_val[0].shape)\n",
    "print(x_train[5][..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data augmentation ###\n",
    "PIXELS = 32\n",
    "imageSize = PIXELS * PIXELS\n",
    "num_features = imageSize\n",
    "\n",
    "# much faster than the standard skimage.transform.warp method\n",
    "def fast_warp(img, tf, output_shape, mode='constant'):\n",
    "    return transform._warps_cy._warp_fast(img, tf.params,output_shape=output_shape, mode=mode)\n",
    "def batch_augment(data):\n",
    "    x_batch_aug = data\n",
    "    # random rotations betweein -10 and 10 degrees\n",
    "    dorotate = np.random.randint(-10,10)\n",
    "\n",
    "    # random translations\n",
    "    trans_1 = np.random.randint(-10,10)\n",
    "    trans_2 = np.random.randint(-10,10)\n",
    "\n",
    "    # random zooms\n",
    "    zoom = np.random.uniform(1, 1.3)\n",
    "\n",
    "    # shearing\n",
    "    shear_deg = np.random.uniform(-25, 25)\n",
    "\n",
    "    # set the transform parameters for skimage.transform.warp\n",
    "    # have to shift to center and then shift back after transformation otherwise\n",
    "    # rotations will make image go out of frame\n",
    "    center_shift   = np.array((PIXELS, PIXELS)) / 2. - 0.5\n",
    "    tform_center   = transform.SimilarityTransform(translation=-center_shift)\n",
    "    tform_uncenter = transform.SimilarityTransform(translation=center_shift)\n",
    "\n",
    "    tform_aug = transform.AffineTransform(rotation = np.deg2rad(dorotate),\n",
    "                                          scale =(1/zoom, 1/zoom),\n",
    "                                          shear = np.deg2rad(shear_deg),\n",
    "                                          translation = (trans_1, trans_2))\n",
    "    tform = tform_center + tform_aug + tform_uncenter\n",
    "    # images in the batch do the augmentation\n",
    "    #print(x_batch_aug.shape[0])\n",
    "    for j in range(x_batch_aug.shape[0]):\n",
    "        #print(x_batch_aug[j][0].shape)\n",
    "        x_batch_aug[j][..., 0] = fast_warp(x_batch_aug[j][..., 0], tform,\n",
    "                                      output_shape = (PIXELS, PIXELS))\n",
    "\n",
    "    # use sobel edge detector filter on one quarter of the images\n",
    "    indices_sobel = np.random.choice(x_batch_aug.shape[0],\n",
    "                                     x_batch_aug.shape[0] // 4, replace = False)\n",
    "    for k in indices_sobel:\n",
    "        img = x_batch_aug[k][0]\n",
    "        x_batch_aug[k][0] = filters.sobel(img)\n",
    "\n",
    "    # invert half of the images\n",
    "    indices_invert = np.random.choice(x_batch_aug.shape[0],\n",
    "                                      x_batch_aug.shape[0] // 2, replace = False)\n",
    "    for l in indices_invert:\n",
    "        img = x_batch_aug[l][0]\n",
    "        x_batch_aug[l][0] = np.absolute(img - np.amax(img))\n",
    "\n",
    "    return  x_batch_aug  \n",
    "\n",
    "def batch_augment2(data):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(percent=0.01), # # 从每侧裁剪图像0到16px（随机选择）\n",
    "        iaa.Fliplr(0.5), # 水平翻转图像 括号内为Probability of each image to get flipped.\n",
    "        iaa.Flipud(0.5), #上下翻转\n",
    "        #iaa.GaussianBlur(sigma=(0, 3.0)),  # 使用0到3.0的sigma模糊图像\n",
    "        iaa.Affine(scale=(0.7, 1.3), translate_percent=0.01, rotate=iap.Normal(-10, 10)),#旋转\n",
    "        iaa.Multiply(iap.Positive(iap.Normal(0.0, 0.1)) + 1.0),#明暗变化\n",
    "        #iaa.AddElementwise(iap.Discretize((iap.Beta(0.5, 0.5) * 2 - 1.0) * 64))\n",
    "        #iaa.AdditiveGaussianNoise(scale=(0,  0.05*255)),\n",
    "        iaa.Sharpen(alpha=0.5),\n",
    "        #iaa.Scale((0.5, 1.5))\n",
    "    ],random_order=True)#每个batch中的Augmenters顺序不一样\n",
    "    x_batch = seq.augment_images(data)\n",
    "    return x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义STN网络 ###\n",
    "#两层定位网络   \n",
    "def ctn_conv(x, is_training):\n",
    "    # Identity transformation\n",
    "    out_size = (32, 32)\n",
    "    initial = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "    initial = initial.astype('float32')\n",
    "    initial = initial.flatten()\n",
    "    b_fc_loc2 = tf.Variable(initial_value=initial, name='b_fc_loc2')\n",
    "    \n",
    "    flatten = tf.reshape(x, [-1, 32*32*1])    \n",
    "    # Frist layer\n",
    "    h_fc_loc1 = tf.nn.tanh(tf.layers.dense(flatten, 20))\n",
    "    if is_training == True:\n",
    "        h_fc_loc1 = tf.layers.dropout(relu5, 0.25)\n",
    "    # Second layer\n",
    "    h_fc_loc2 = tf.nn.tanh(tf.layers.dense(h_fc_loc1, 6, use_bias=False) + b_fc_loc2)\n",
    "    #h_fc_loc2 = tf.nn.tanh(tf.matmul(h_fc_loc1_drop, W_fc_loc2) + b_fc_loc2)\n",
    "    h_trans = transformer(x, h_fc_loc2, out_size)\n",
    "    return h_trans\n",
    "def ctn_conv2(x, is_training):\n",
    "    out_size = (32, 32)\n",
    "    #定位特征提取网络\n",
    "    with tf.variable_scope('location'):\n",
    "        conv1 = tf.layers.conv2d(x, 8, 3, strides=1, padding='SAME')\n",
    "        norm1 = tf.layers.batch_normalization(conv1, center=True, scale=True, training=is_training)\n",
    "        relu1 = tf.nn.relu(norm1)\n",
    "        pool1 = tf.layers.max_pooling2d(relu1, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(pool1, 10, 3, strides=1, padding='SAME')\n",
    "        norm2 = tf.layers.batch_normalization(conv2, center=True, scale=True, training=is_training)\n",
    "        rule2 = tf.nn.relu(norm2)\n",
    "        pool1 = tf.layers.max_pooling2d(rule2, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('regression'):\n",
    "        flatten = tf.reshape(pool1, [-1, 8*8*10])\n",
    "        fc1 = tf.layers.dense(flatten, 32)\n",
    "        relu3 = tf.nn.relu(fc1)\n",
    "        if is_training == True:\n",
    "            relu3 = tf.layers.dropout(relu3, 0.5)\n",
    "        fc2 = tf.layers.dense(relu3, 6)\n",
    "    h_trans = transformer(x, fc2, out_size)\n",
    "    return h_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###定义模型###\n",
    "def model(x, classes, is_training):\n",
    "    '''\n",
    "    #stn网络，loss降不下来，反而上升，比原来效果差很多，基本不可用\n",
    "    #在MNIST数据集上可用，推测STN网络应该适合应用于背景比较大的样本\n",
    "    with tf.variable_scope('layer0-STN'): \n",
    "        stn = ctn_conv2(x, is_training)\n",
    "    '''\n",
    "    with tf.variable_scope('layer1-conv'):\n",
    "        conv1 = tf.layers.conv2d(x, 128, 3, strides=1, padding='SAME')\n",
    "        norm1 = tf.layers.batch_normalization(conv1, center=True, scale=True, training=is_training)\n",
    "        relu1 = tf.nn.relu(norm1)\n",
    "    with tf.variable_scope('layer2-conv-pool'):\n",
    "        conv2 = tf.layers.conv2d(relu1, 128, 3, strides=1, padding='SAME')\n",
    "        norm2 = tf.layers.batch_normalization(conv2, center=True, scale=True, training=is_training)\n",
    "        relu2 = tf.nn.relu(norm2)\n",
    "        pool2 = tf.layers.max_pooling2d(relu2, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer3-conv'):\n",
    "        conv3 = tf.layers.conv2d(pool2, 256, 3, strides=1, padding='SAME')\n",
    "        norm3 = tf.layers.batch_normalization(conv3, center=True, scale=True, training=is_training)\n",
    "        relu3 = tf.nn.relu(norm3)\n",
    "    with tf.variable_scope('layer4-conv-pool'):\n",
    "        conv4 = tf.layers.conv2d(relu3, 256, 3, strides=1, padding='SAME')\n",
    "        norm4 = tf.layers.batch_normalization(conv4, center=True, scale=True, training=is_training)\n",
    "        relu4 = tf.nn.relu(norm4)\n",
    "        pool4 = tf.layers.max_pooling2d(relu4, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer5-conv'):\n",
    "        conv5 = tf.layers.conv2d(pool4, 512, 3, strides=1, padding='SAME')\n",
    "        norm5 = tf.layers.batch_normalization(conv5, center=True, scale=True, training=is_training)\n",
    "        relu5 = tf.nn.relu(norm5)\n",
    "    with tf.variable_scope('layer6-conv'):\n",
    "        conv6 = tf.layers.conv2d(relu5, 512, 3, strides=1, padding='SAME')\n",
    "        norm6 = tf.layers.batch_normalization(conv6, center=True, scale=True, training=is_training)\n",
    "        relu6 = tf.nn.relu(norm6) \n",
    "    with tf.variable_scope('layer7-conv-pool'):\n",
    "        conv7 = tf.layers.conv2d(relu6, 512, 3, strides=1, padding='SAME')\n",
    "        norm7 = tf.layers.batch_normalization(conv7, center=True, scale=True, training=is_training)\n",
    "        relu7 = tf.nn.relu(norm7)\n",
    "        pool7 = tf.layers.max_pooling2d(relu7, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    with tf.variable_scope('layer8-FC'):\n",
    "        flatten = tf.reshape(pool7, [-1, 4*4*512])\n",
    "        affine8 = tf.layers.dense(flatten, 4096)\n",
    "        norm8 = tf.layers.batch_normalization(affine8, center=True, scale=True, training=is_training)\n",
    "        relu8 = tf.nn.relu(norm8)\n",
    "        if is_training == True:\n",
    "            relu8 = tf.layers.dropout(relu8, 0.5)   \n",
    "    with tf.variable_scope('layer9-FC'):\n",
    "        affine9 = tf.layers.dense(relu8, 4096)\n",
    "        norm9 = tf.layers.batch_normalization(affine9, center=True, scale=True, training=is_training)\n",
    "        relu9 = tf.nn.relu(norm9)\n",
    "        if is_training == True:\n",
    "            relu9 = tf.layers.dropout(relu9, 0.5)\n",
    "    with tf.variable_scope('layer10-FC'):\n",
    "        output = tf.layers.dense(relu9, classes)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss is 3.897062 validataion loss is 4.230770 accuracy is 0.160000\n",
      "epoch 5 train loss is 0.847832 validataion loss is 1.897475 accuracy is 0.640000\n",
      "epoch 10 train loss is 0.373312 validataion loss is 1.512475 accuracy is 0.680000\n",
      "epoch 15 train loss is 0.307937 validataion loss is 1.271813 accuracy is 0.740000\n",
      "epoch 20 train loss is 0.150713 validataion loss is 1.234398 accuracy is 0.750000\n",
      "epoch 25 train loss is 0.099768 validataion loss is 1.664895 accuracy is 0.765000\n",
      "epoch 30 train loss is 0.038349 validataion loss is 1.232800 accuracy is 0.735000\n",
      "epoch 35 train loss is 0.087021 validataion loss is 1.263785 accuracy is 0.770000\n",
      "epoch 40 train loss is 0.049804 validataion loss is 1.232045 accuracy is 0.750000\n",
      "epoch 45 train loss is 0.014133 validataion loss is 1.384455 accuracy is 0.745000\n",
      "epoch 50 train loss is 0.015281 validataion loss is 1.144700 accuracy is 0.805000\n",
      "epoch 55 train loss is 0.055982 validataion loss is 1.254721 accuracy is 0.745000\n",
      "epoch 60 train loss is 0.018152 validataion loss is 1.187463 accuracy is 0.755000\n",
      "epoch 65 train loss is 0.033666 validataion loss is 1.328241 accuracy is 0.770000\n",
      "epoch 70 train loss is 0.015767 validataion loss is 1.344460 accuracy is 0.790000\n",
      "epoch 75 train loss is 0.028944 validataion loss is 1.506831 accuracy is 0.740000\n",
      "epoch 80 train loss is 0.020313 validataion loss is 2.226902 accuracy is 0.640000\n",
      "epoch 85 train loss is 0.015761 validataion loss is 1.674210 accuracy is 0.755000\n",
      "epoch 90 train loss is 0.026710 validataion loss is 1.592272 accuracy is 0.755000\n",
      "epoch 95 train loss is 0.016292 validataion loss is 1.617842 accuracy is 0.725000\n",
      "epoch 100 train loss is 0.032207 validataion loss is 1.629617 accuracy is 0.725000\n",
      "epoch 105 train loss is 0.007235 validataion loss is 1.511018 accuracy is 0.755000\n",
      "epoch 110 train loss is 0.004519 validataion loss is 1.679919 accuracy is 0.755000\n",
      "epoch 115 train loss is 0.001313 validataion loss is 1.604274 accuracy is 0.760000\n",
      "epoch 120 train loss is 0.007715 validataion loss is 1.513292 accuracy is 0.750000\n",
      "epoch 125 train loss is 0.003595 validataion loss is 1.339647 accuracy is 0.815000\n",
      "epoch 130 train loss is 0.003239 validataion loss is 1.656230 accuracy is 0.770000\n",
      "epoch 135 train loss is 0.004387 validataion loss is 1.587123 accuracy is 0.785000\n",
      "epoch 140 train loss is 0.001013 validataion loss is 1.363612 accuracy is 0.760000\n",
      "epoch 145 train loss is 0.001466 validataion loss is 1.644310 accuracy is 0.740000\n",
      "epoch 150 train loss is 0.000188 validataion loss is 1.627938 accuracy is 0.750000\n",
      "early stoping\n"
     ]
    }
   ],
   "source": [
    "### 训练 ###\n",
    "#训练参数\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500             #迭代次数\n",
    "EARLY_STOP_PATIENCE = 100 #控制early stopping的参数\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "y_data = tf.placeholder(tf.float32, [None, 62])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "ckpt_path = './model/mode.ckpt'\n",
    "\n",
    "predict = model(x_data, 62, is_training)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=y_data))\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):#批归一化层\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(predict, 1), tf.argmax(y_data, 1)), tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    best_validation_loss = 1000000.0\n",
    "    current_epoch = 0\n",
    "    \n",
    "    epoch = EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    train_size = len(x_train)\n",
    "    train_index = list(range(train_size))\n",
    "    for n in range(epoch):\n",
    "        random.shuffle(train_index)  # 每个epoch都shuffle一下效果更好\n",
    "        x_train_, y_train_ = x_train[train_index], y_train[train_index]\n",
    "        #添加交叉验证\n",
    "        #x_train, x_val, y_train, y_val = train_test_split(train_img, train_y, test_size=0.1, random_state=42, shuffle=True)\n",
    "        for i in range(0, train_size, batch_size):\n",
    "            x_batch = x_train_[i : i + batch_size]\n",
    "            y_batch = y_train_[i : i + batch_size]\n",
    "            _, loss_step = sess.run([train_step, loss], \\\n",
    "                             feed_dict={x_data:x_batch, y_data:y_batch, is_training:True})\n",
    "            #数据扩充\n",
    "            x_batch_aug = batch_augment2(x_batch)\n",
    "            _, loss_aug = sess.run([train_step, loss], \\\n",
    "                                    feed_dict={x_data:x_batch_aug, y_data:y_batch, is_training:True})\n",
    "        if n % 5 == 0:\n",
    "            validation_loss, accuracy = sess.run([loss, acc], feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            #validation_loss = loss.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            #accuracy = acc.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "            print(\"epoch %d train loss is %f validataion loss is %f accuracy is %f\" % (n, loss_step, validation_loss, accuracy))\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            current_epoch = n\n",
    "            saver.save(sess, ckpt_path)\n",
    "        elif (n - current_epoch) >= EARLY_STOP_PATIENCE:\n",
    "            print('early stoping')\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 计算混淆矩阵  ###\n",
    "def testModel(ckpt_path):\n",
    "    tf.reset_default_graph()#mo\n",
    "    x_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "    y_data = tf.placeholder(tf.float32, [None, 62])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    out = model(x_data, 62, is_training)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1), tf.argmax(y_data, 1)), tf.float32))\n",
    "    saver = tf.train.Saver() \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, ckpt_path)\n",
    "        #sess.run(out, feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "        y_hat = out.eval({x_data: x_val, is_training:False})\n",
    "        y_pred = np.argmax(y_hat, axis=1)\n",
    "        y_true = np.argmax(y_val, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        '''\n",
    "        for i in range(cm.shape[0]):# 混淆矩阵\n",
    "            for j in range(cm.shape[1]):\n",
    "                print(cm[i][j], end=' ')\n",
    "            print('\\n')\n",
    "        '''\n",
    "        print(cm)\n",
    "        acc = accuracy.eval(feed_dict={x_data:x_val, y_data:y_val, is_training:False})\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mode.ckpt\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "0.735\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"./model/mode.ckpt\"\n",
    "testModel(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Submit ###\n",
    "def submit(model_save_path, output_file):\n",
    "    tf.reset_default_graph()\n",
    "    x_test_data = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    logits = model(x_test_data, 62, is_training)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, model_save_path)\n",
    "        \n",
    "        y_pred = []\n",
    "        test_size = len(test_all)\n",
    "        batch_size = 1\n",
    "        for i in range(0, test_size, batch_size):\n",
    "            x_test_batch = test_all[i*batch_size : (i+1)*batch_size]\n",
    "            y_hat = logits.eval({x_test_data: x_test_batch, is_training:False})\n",
    "            y_pred_batch = np.argmax(y_hat, axis=1)\n",
    "            #vInt2label = np.vectorize(int2label)\n",
    "            y_pred.append(int2label(y_pred_batch))      \n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write('ID,Class\\n')\n",
    "            for i in range(len(y_pred)):\n",
    "                f.write(\"\".join([str(i+6284), ',', y_pred[i], '\\n']))\n",
    "        print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mode.ckpt\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./model/mode.ckpt\"\n",
    "output_file = \"submission.csv\"\n",
    "submit(model_save_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
