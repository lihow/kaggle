{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用vgg提取每一类的平均的特征，保存特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "#from progressbar import * #进度条\n",
    "from tqdm import tqdm #进度条\n",
    "from torchnet import meter\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F #torch是关于运算的包\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets,transforms, models #torchvision则是打包了一些数据集\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 再次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"data/train.csv\")\n",
    "temp_df = train_csv.groupby('Id').count()\n",
    "#temp_df_subset = temp_df[temp_df.Image == 1]\n",
    "temp_df_subset = temp_df[temp_df.Image >= 30]\n",
    "#print(temp_df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = torchvision.datasets.ImageFolder('data/net_classes',\n",
    "                                            transform = transforms.Compose([\n",
    "                                                transforms.Grayscale(3),\n",
    "                                                transforms.Resize((224, 224)),\n",
    "                                                T.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor()\n",
    "                                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "10\n",
      "train len is 1325\n"
     ]
    }
   ],
   "source": [
    "print(traindata[0][0].shape)\n",
    "print(traindata[454][1])#打印标签\n",
    "print('train len is %d' % len(traindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = models.vgg16(pretrained=True)\n",
    "for parma in pre_model.parameters():\n",
    "    parma.requires_grad = False\n",
    "pre_model.classifier = torch.nn.Sequential(torch.nn.Linear(25088, 4096),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(4096, 2048),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Dropout(p=0.5),\n",
    "                                       torch.nn.Linear(2048, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "#print(pre_model)\n",
    "net = pre_model\n",
    "y = net(torch.randn(1, 3, 224, 224))\n",
    "#print(net)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_path, train_dataset):\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "    net = pre_model\n",
    "    #接着上一次训练\n",
    "    if os.path.exists(model_path):\n",
    "        net = torch.load(model_path)\n",
    "    net = net.cuda()\n",
    "    #调整学习率参数\n",
    "    lr = 0.001\n",
    "    lr_decay = 0.995\n",
    "    weight_decay = 1e-4\n",
    "    pre_train_loss = 100000\n",
    "    \n",
    "    # CrossEntropyLoss就是我们需要的损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #统计指标\n",
    "    #loss_meter = meter.AverageValueMeter()\n",
    "    #保存模型判断条件\n",
    "    max_train_acc = 0\n",
    "    pre_epoch = 0\n",
    "    max_interval_epoch = 10\n",
    "\n",
    "    \n",
    "    print(\"Start Training...\")\n",
    "    for epoch in range(100):\n",
    "        #训练集\n",
    "        train_loss = 0\n",
    "        train_count = 0\n",
    "        train_acc = 0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            #inputs, labels = inputs.to(device), labels.to(device) # 注意需要复制到GPU\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #更新指标\n",
    "            train_count += labels.size(0)\n",
    "            train_loss += loss.item()\n",
    "            _, predict = outputs.max(1)\n",
    "            train_acc += (predict == labels).sum().item()\n",
    "        train_loss /= train_count\n",
    "        train_acc /= train_count\n",
    "        \n",
    "        print('the epoch %d, the train loss is %f, the trian acc is %f' % (epoch, train_loss, train_acc))\n",
    "        \n",
    "        #保存模型\n",
    "        if train_acc > max_train_acc:\n",
    "            max_train_acc = train_acc\n",
    "            pre_epoch = epoch\n",
    "            torch.save(net, model_path)#保存整个神经网络的的结构信息和模型参数信息，save的对象是网络net\n",
    "        if epoch - pre_epoch > max_interval_epoch:\n",
    "            print('early stop')\n",
    "            break\n",
    "            \n",
    "        #如果损失不载下降，则降低学习率\n",
    "        if train_loss > pre_train_loss:\n",
    "            lr = lr*lr_decay\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        pre_train_loss = pre_train_loss\n",
    "    print(\"Done Training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "the epoch 0, the train loss is 0.023060, the trian acc is 0.174340\n",
      "the epoch 1, the train loss is 0.022088, the trian acc is 0.204528\n",
      "the epoch 2, the train loss is 0.021750, the trian acc is 0.221132\n",
      "the epoch 3, the train loss is 0.020545, the trian acc is 0.264151\n",
      "the epoch 4, the train loss is 0.018870, the trian acc is 0.313962\n",
      "the epoch 5, the train loss is 0.016643, the trian acc is 0.396226\n",
      "the epoch 6, the train loss is 0.013860, the trian acc is 0.487547\n",
      "the epoch 7, the train loss is 0.010813, the trian acc is 0.598491\n",
      "the epoch 8, the train loss is 0.008971, the trian acc is 0.669434\n",
      "the epoch 9, the train loss is 0.007110, the trian acc is 0.732075\n",
      "the epoch 10, the train loss is 0.006102, the trian acc is 0.763774\n",
      "the epoch 11, the train loss is 0.005536, the trian acc is 0.784906\n",
      "the epoch 12, the train loss is 0.004770, the trian acc is 0.812075\n",
      "the epoch 13, the train loss is 0.003989, the trian acc is 0.855094\n",
      "the epoch 14, the train loss is 0.003835, the trian acc is 0.848302\n",
      "the epoch 15, the train loss is 0.003464, the trian acc is 0.867925\n",
      "the epoch 16, the train loss is 0.002878, the trian acc is 0.885283\n",
      "the epoch 17, the train loss is 0.002750, the trian acc is 0.900377\n",
      "the epoch 18, the train loss is 0.002627, the trian acc is 0.901887\n",
      "the epoch 19, the train loss is 0.002909, the trian acc is 0.892830\n",
      "the epoch 20, the train loss is 0.002320, the trian acc is 0.910189\n",
      "the epoch 21, the train loss is 0.002178, the trian acc is 0.916981\n",
      "the epoch 22, the train loss is 0.002367, the trian acc is 0.903396\n",
      "the epoch 23, the train loss is 0.002305, the trian acc is 0.920755\n",
      "the epoch 24, the train loss is 0.002028, the trian acc is 0.935849\n",
      "the epoch 25, the train loss is 0.001945, the trian acc is 0.926792\n",
      "the epoch 26, the train loss is 0.001749, the trian acc is 0.938868\n",
      "the epoch 27, the train loss is 0.001904, the trian acc is 0.935094\n",
      "the epoch 28, the train loss is 0.002155, the trian acc is 0.920755\n",
      "the epoch 29, the train loss is 0.001915, the trian acc is 0.929811\n",
      "the epoch 30, the train loss is 0.002397, the trian acc is 0.928302\n",
      "the epoch 31, the train loss is 0.001597, the trian acc is 0.934340\n",
      "the epoch 32, the train loss is 0.001990, the trian acc is 0.935094\n",
      "the epoch 33, the train loss is 0.001760, the trian acc is 0.935849\n",
      "the epoch 34, the train loss is 0.001687, the trian acc is 0.938868\n",
      "the epoch 35, the train loss is 0.001385, the trian acc is 0.950943\n",
      "the epoch 36, the train loss is 0.001262, the trian acc is 0.954717\n",
      "the epoch 37, the train loss is 0.001477, the trian acc is 0.949434\n",
      "the epoch 38, the train loss is 0.001176, the trian acc is 0.957736\n",
      "the epoch 39, the train loss is 0.001154, the trian acc is 0.963774\n",
      "the epoch 40, the train loss is 0.001538, the trian acc is 0.957736\n",
      "the epoch 41, the train loss is 0.001262, the trian acc is 0.952453\n",
      "the epoch 42, the train loss is 0.001882, the trian acc is 0.942642\n",
      "the epoch 43, the train loss is 0.001506, the trian acc is 0.944906\n",
      "the epoch 44, the train loss is 0.001572, the trian acc is 0.945660\n",
      "the epoch 45, the train loss is 0.002010, the trian acc is 0.938868\n",
      "the epoch 46, the train loss is 0.001593, the trian acc is 0.943396\n",
      "the epoch 47, the train loss is 0.001456, the trian acc is 0.946415\n",
      "the epoch 48, the train loss is 0.001588, the trian acc is 0.943396\n",
      "the epoch 49, the train loss is 0.001830, the trian acc is 0.938113\n",
      "the epoch 50, the train loss is 0.001440, the trian acc is 0.942642\n",
      "early stop\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "train('model/funtune_vgg16.pkl', traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=25088, out_features=4096, bias=True) ReLU() Dropout(p=0.5) Linear(in_features=4096, out_features=2048, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(*list(pre_model.classifier.children())[:-3])\n",
    "#print(pre_model.features)\n",
    "#vgg_model = models.vgg16(pretrained=True)\n",
    "#print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg_model = models.vgg16(pretrained=True)\n",
    "#print(vgg_model)\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    提取vgg的4096向量\n",
    "    '''\n",
    "    def __init__(self, model_path):\n",
    "        super(Encoder, self).__init__()\n",
    "        VGG = torch.load(model_path)\n",
    "        self.feature = VGG.features\n",
    "        self.classifier = nn.Sequential(*list(VGG.classifier.children())[:-3])\n",
    "        pretrained_dict = VGG.state_dict()\n",
    "        model_dict = self.classifier.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.classifier.load_state_dict(model_dict)\n",
    "    def forward(self, x):\n",
    "        output = self.feature(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "#print(pre_model)\n",
    "model = Encoder('model/funtune_vgg16.pkl')\n",
    "model = model.cuda()\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "x = x.cuda()\n",
    "y = model(x)\n",
    "#print(net)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Encoder())\n",
    "def extractor(img_path, net):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    img = Variable(torch.unsqueeze(img, dim=0).float(), requires_grad=False)#增加一维\n",
    "    #print(img.shape)\n",
    "    net = net.cuda()\n",
    "    net.eval()\n",
    "    img = img.cuda()\n",
    "    y = net(img).cpu()\n",
    "    y = torch.squeeze(y)\n",
    "    y = y.data.numpy()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00475063  0.23318964  0.7165816  ... -0.6850112  -1.4086967\n",
      "  0.37565774]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/train/1cf255a78.jpg'\n",
    "model_path = 'model/funtune_vgg16.pkl'\n",
    "feature = extractor(img_path, Encoder(model_path))\n",
    "#feature = extractor(img_path, Encoder())\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_train_feature(dir_path, model, feature_dim=2048):\n",
    "    data = np.zeros((1, feature_dim))\n",
    "    label = []\n",
    "    for file in tqdm(os.listdir(dir_path)):\n",
    "        if file == 'new_whale':\n",
    "            continue\n",
    "        path = os.path.join(dir_path, file)\n",
    "        if os.path.isdir(path):\n",
    "            feature_tmp = np.zeros((1, feature_dim))\n",
    "            label_name = file\n",
    "            img_num = 0\n",
    "            for img in os.listdir(path):\n",
    "                img_path = os.path.join(path, img)\n",
    "                feature = extractor(img_path, model)\n",
    "                img_num += 1\n",
    "                feature_tmp += feature\n",
    "            if img_num > 0:\n",
    "                feature = feature_tmp / img_num\n",
    "                data = np.concatenate((data, feature))\n",
    "                label.append(label_name)\n",
    "    data = data[1:, :]\n",
    "    np.savetxt('model/train_feature.txt', data, fmt='%f')\n",
    "    label_file = open('model/label.txt', 'w')\n",
    "    json.dump(label, label_file)\n",
    "    label_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5005/5005 [19:54<00:00,  6.59it/s]  \n"
     ]
    }
   ],
   "source": [
    "extract_train_feature('data/train_classes',  Encoder(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到最近的5个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.loadtxt('model/train_feature.txt', dtype=float)\n",
    "train_labels = open('model/label.txt', 'r')\n",
    "labels = json.load(train_labels)\n",
    "train_labels.close()\n",
    "#print(train_features)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_classes(test_feature, train_features, labels):\n",
    "    #print(train_features.shape)\n",
    "    distance = train_features - test_feature\n",
    "    euclidean_distance = np.linalg.norm(distance, axis=1, keepdims=True)\n",
    "    euclidean_distance = euclidean_distance.flatten()\n",
    "    min_distance_idx = np.argsort(euclidean_distance)[:5]\n",
    "    min_distance = np.sort(euclidean_distance)[:5]\n",
    "    #print(min_distance)\n",
    "    classes = []\n",
    "    for idx in min_distance_idx:\n",
    "        if euclidean_distance[idx] > 40:\n",
    "            classes.append('new_whale')\n",
    "        else:\n",
    "            classes.append(labels[idx])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w_564a34b', 'w_05eb863', 'w_9b16b48', 'w_c3c0d22', 'new_whale']\n"
     ]
    }
   ],
   "source": [
    "test_img = 'data/train/d9e958ed9.jpg'\n",
    "feature = extractor(test_img, Encoder(model_path))\n",
    "predict_label = top_5_classes(feature, train_features, labels)\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submmit(test_floder, model, output_file):\n",
    "    files = natsorted(glob.glob(test_floder + '/*'))\n",
    "    f = open(output_file, 'w')\n",
    "    f.write('Image,Id\\n')\n",
    "    for file in tqdm(files):\n",
    "        feature = extractor(file, model)\n",
    "        top_5 = top_5_classes(feature, train_features, labels)\n",
    "        img_name = file.split('/')[-1]\n",
    "        f.write(' '.join([img_name+',', top_5[0], top_5[1], top_5[2], top_5[3],top_5[4], '\\n']))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7960/7960 [22:22<00:00,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "submmit('data/test', Encoder(model_path), 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
