{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用vgg提取每一类的平均的特征，保存特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "#from progressbar import * #进度条\n",
    "from tqdm import tqdm #进度条\n",
    "from torchnet import meter\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F #torch是关于运算的包\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets,transforms, models #torchvision则是打包了一些数据集\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg_model = models.vgg16(pretrained=True)\n",
    "#print(vgg_model)\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    提取vgg的4096向量\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        VGG = models.vgg16(pretrained=True)\n",
    "        self.feature = VGG.features\n",
    "        self.classifier = nn.Sequential(*list(VGG.classifier.children())[:-3])\n",
    "        pretrained_dict = VGG.state_dict()\n",
    "        model_dict = self.classifier.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.classifier.load_state_dict(model_dict)\n",
    "    def forward(self, x):\n",
    "        output = self.feature(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Encoder())\n",
    "def extractor(img_path, net):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = transform(img)\n",
    "    img = Variable(torch.unsqueeze(img, dim=0).float(), requires_grad=False)#增加一维\n",
    "    \n",
    "    net = net.cuda()\n",
    "    img = img.cuda()\n",
    "    y = net(img).cpu()\n",
    "    y = torch.squeeze(y)\n",
    "    y = y.data.numpy()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/train/1cf255a78.jpg'\n",
    "feature = extractor(img_path, Encoder())\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_train_feature(dir_path, model, feature_dim=4096):\n",
    "    data = np.zeros((1, feature_dim))\n",
    "    label = []\n",
    "    for file in tqdm(os.listdir(dir_path)):\n",
    "        if file == 'new_whale':\n",
    "            continue\n",
    "        path = os.path.join(dir_path, file)\n",
    "        if os.path.isdir(path):\n",
    "            feature_tmp = np.zeros((1, feature_dim))\n",
    "            label_name = file\n",
    "            img_num = 0\n",
    "            for img in os.listdir(path):\n",
    "                img_path = os.path.join(path, img)\n",
    "                feature = extractor(img_path, model)\n",
    "                img_num += 1\n",
    "                feature_tmp += feature\n",
    "            if img_num > 0:\n",
    "                feature = feature_tmp / img_num\n",
    "                data = np.concatenate((data, feature))\n",
    "                label.append(label_name)\n",
    "    data = data[1:, :]\n",
    "    np.savetxt('model/train_feature.txt', data, fmt='%f')\n",
    "    label_file = open('model/label.txt', 'w')\n",
    "    json.dump(label, label_file)\n",
    "    label_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5005/5005 [10:12<00:00,  8.17it/s]\n"
     ]
    }
   ],
   "source": [
    "extract_train_feature('data/train_classes', Encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到最近的5个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_classes(test_feature):\n",
    "    train_features = np.loadtxt('model/train_feature.txt', dtype=float)\n",
    "    train_labels = open('model/label.txt', 'r')\n",
    "    labels = json.load(train_labels)\n",
    "    train_labels.close()\n",
    "    \n",
    "    distance = train_features - test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
